{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **Automatidata project**\n",
    "**Course 6 - The Nuts and bolts of machine learning**/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ttxbfHXzB4e"
   },
   "source": [
    "You are a data professional in a data analytics firm called Automatidata. Their client, the New York City Taxi & Limousine Commission (New York City TLC), was impressed with the work you have done and has requested that you build a machine learning model to predict if a customer will not leave a tip. They want to use the model in an app that will alert taxi drivers to customers who are unlikely to tip, since drivers depend on tips.\n",
    "\n",
    "A notebook was structured and prepared to help you in this project. Please complete the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# Course 6 End-of-course project: Build a machine learning model\n",
    "\n",
    "In this activity, you will practice using tree-based modeling techniques to predict on a binary target class.  \n",
    "<br/>   \n",
    "\n",
    "**The purpose** of this model is to find ways to generate more revenue for taxi cab drivers.  \n",
    "  \n",
    "**The goal** of this model is to predict whether or not a customer is a generous tipper.  \n",
    "<br/>  \n",
    "\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** Ethical considerations \n",
    "* Consider the ethical implications of the request \n",
    "\n",
    "* Should the objective of the model be adjusted?\n",
    "\n",
    "**Part 2:** Feature engineering\n",
    "\n",
    "* Perform feature selection, extraction, and transformation to prepare the data for modeling\n",
    "\n",
    "**Part 3:** Modeling\n",
    "\n",
    "* Build the models, evaluate them, and advise on next steps\n",
    "\n",
    "Follow the instructions and answer the questions below to complete the activity. Then, complete an Executive Summary using the questions listed on the PACE Strategy Document. \n",
    "\n",
    "Be sure to complete this activity before moving on. The next course item will provide you with a completed exemplar to compare to your own work. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzDjfCSLf6Jq"
   },
   "source": [
    "<img src=\"images/Pace.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "# **PACE stages**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout these project notebooks, you'll see references to the problem-solving framework PACE. The following notebook components are labeled with the respective PACE stage: Plan, Analyze, Construct, and Execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5g1A74r0ow_"
   },
   "source": [
    "<img src=\"images/Plan.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "\n",
    "## PACE: Plan \n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Plan stage.\n",
    "\n",
    "In this stage, consider the following questions:\n",
    "\n",
    "1.   What are you being asked to do?\n",
    "\n",
    "\n",
    "2.   What are the ethical implications of the model? What are the consequences of your model making errors?\n",
    "  *   What is the likely effect of the model when it predicts a false negative (i.e., when the model says a customer will give a tip, but they actually won't)?\n",
    "  \n",
    "  *   What is the likely effect of the model when it predicts a false positive (i.e., when the model says a customer will not give a tip, but they actually will)?  \n",
    "  \n",
    "  \n",
    "3.   Do the benefits of such a model outweigh the potential problems?\n",
    "  \n",
    "4.   Would you proceed with the request to build this model? Why or why not?\n",
    " \n",
    "5.   Can the objective be modified to make it less problematic?\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> ENTER YOUR RESPONSES TO QUESTIONS 1-5 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUUrVKTe4cc5"
   },
   "source": [
    "Suppose you were to modify the modeling objective so, instead of predicting people who won't tip at all, you predicted people who are particularly generous&mdash;those who will tip 20% or more? Consider the following questions:\n",
    "\n",
    "1.  What features do you need to make this prediction?\n",
    "\n",
    "2.  What would be the target variable?  \n",
    "\n",
    "3.  What metric should you use to evaluate your model? Do you have enough information to decide this now?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> ENTER YOUR RESPONSES TO QUESTIONS 1-3 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**_Complete the following steps to begin:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8Vm3QEfGELS"
   },
   "source": [
    "\n",
    "### **Task 1. Imports and data loading**\n",
    "\n",
    "Import packages and libraries needed to build and evaluate random forest and XGBoost classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fKhnX2Puf4Bt"
   },
   "outputs": [],
   "source": [
    "# Import packages and libraries\n",
    "### YOUR CODE HERE ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO SEE ALL COLUMNS \n",
    "# This lets us see all of the columns, preventing Juptyer from redacting them.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "pd.set_option('display.max_column',25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeXTZ2tdbALL"
   },
   "source": [
    "Begin by reading in the data. There are two dataframes: one containing the original data, the other containing the mean durations, mean distances, and predicted fares from the previous course's project called nyc_preds_means.csv.\n",
    "\n",
    "**Note:** `Pandas` reads in the dataset as `df0`, now inspect the first five rows. As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5weTXGKqa_iG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22699, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THE CELL BELOW TO IMPORT YOUR DATA. \n",
    "\n",
    "# Load dataset into dataframe\n",
    "df0 = pd.read_csv('2017_Yellow_Taxi_Trip_Data.csv',index_col='Unnamed: 0')\n",
    "\n",
    "# Import predicted fares and mean distance and duration from previous course\n",
    "nyc_preds_means = pd.read_csv('nyc_preds_means.csv')\n",
    "nyc_preds_means.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the first few rows of `df0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24870114</th>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634249</th>\n",
       "      <td>1</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106203690</th>\n",
       "      <td>1</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38942136</th>\n",
       "      <td>2</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30841670</th>\n",
       "      <td>2</td>\n",
       "      <td>04/15/2017 11:32:20 PM</td>\n",
       "      <td>04/15/2017 11:49:03 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23345809</th>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:34:11 PM</td>\n",
       "      <td>03/25/2017 8:42:11 PM</td>\n",
       "      <td>6</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37660487</th>\n",
       "      <td>2</td>\n",
       "      <td>05/03/2017 7:04:09 PM</td>\n",
       "      <td>05/03/2017 8:03:47 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>12.83</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>59.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69059411</th>\n",
       "      <td>2</td>\n",
       "      <td>08/15/2017 5:41:06 PM</td>\n",
       "      <td>08/15/2017 6:03:05 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>237</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8433159</th>\n",
       "      <td>2</td>\n",
       "      <td>02/04/2017 4:17:07 PM</td>\n",
       "      <td>02/04/2017 4:29:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>249</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95294817</th>\n",
       "      <td>1</td>\n",
       "      <td>11/10/2017 3:20:29 PM</td>\n",
       "      <td>11/10/2017 3:40:55 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  \\\n",
       "24870114          2   03/25/2017 8:55:43 AM   03/25/2017 9:09:47 AM   \n",
       "35634249          1   04/11/2017 2:53:28 PM   04/11/2017 3:19:58 PM   \n",
       "106203690         1   12/15/2017 7:26:56 AM   12/15/2017 7:34:08 AM   \n",
       "38942136          2   05/07/2017 1:17:59 PM   05/07/2017 1:48:14 PM   \n",
       "30841670          2  04/15/2017 11:32:20 PM  04/15/2017 11:49:03 PM   \n",
       "23345809          2   03/25/2017 8:34:11 PM   03/25/2017 8:42:11 PM   \n",
       "37660487          2   05/03/2017 7:04:09 PM   05/03/2017 8:03:47 PM   \n",
       "69059411          2   08/15/2017 5:41:06 PM   08/15/2017 6:03:05 PM   \n",
       "8433159           2   02/04/2017 4:17:07 PM   02/04/2017 4:29:14 PM   \n",
       "95294817          1   11/10/2017 3:20:29 PM   11/10/2017 3:40:55 PM   \n",
       "\n",
       "           passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "24870114                 6           3.34           1                  N   \n",
       "35634249                 1           1.80           1                  N   \n",
       "106203690                1           1.00           1                  N   \n",
       "38942136                 1           3.70           1                  N   \n",
       "30841670                 1           4.37           1                  N   \n",
       "23345809                 6           2.30           1                  N   \n",
       "37660487                 1          12.83           1                  N   \n",
       "69059411                 1           2.98           1                  N   \n",
       "8433159                  1           1.20           1                  N   \n",
       "95294817                 1           1.60           1                  N   \n",
       "\n",
       "           PULocationID  DOLocationID  payment_type  fare_amount  extra  \\\n",
       "24870114            100           231             1         13.0    0.0   \n",
       "35634249            186            43             1         16.0    0.0   \n",
       "106203690           262           236             1          6.5    0.0   \n",
       "38942136            188            97             1         20.5    0.0   \n",
       "30841670              4           112             2         16.5    0.5   \n",
       "23345809            161           236             1          9.0    0.5   \n",
       "37660487             79           241             1         47.5    1.0   \n",
       "69059411            237           114             1         16.0    1.0   \n",
       "8433159             234           249             2          9.0    0.0   \n",
       "95294817            239           237             1         13.0    0.0   \n",
       "\n",
       "           mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "24870114       0.5        2.76           0.0                    0.3   \n",
       "35634249       0.5        4.00           0.0                    0.3   \n",
       "106203690      0.5        1.45           0.0                    0.3   \n",
       "38942136       0.5        6.39           0.0                    0.3   \n",
       "30841670       0.5        0.00           0.0                    0.3   \n",
       "23345809       0.5        2.06           0.0                    0.3   \n",
       "37660487       0.5        9.86           0.0                    0.3   \n",
       "69059411       0.5        1.78           0.0                    0.3   \n",
       "8433159        0.5        0.00           0.0                    0.3   \n",
       "95294817       0.5        2.75           0.0                    0.3   \n",
       "\n",
       "           total_amount  \n",
       "24870114          16.56  \n",
       "35634249          20.80  \n",
       "106203690          8.75  \n",
       "38942136          27.69  \n",
       "30841670          17.80  \n",
       "23345809          12.36  \n",
       "37660487          59.16  \n",
       "69059411          19.58  \n",
       "8433159            9.80  \n",
       "95294817          16.55  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first few rows of df0\n",
    "### YOUR CODE HERE ###\n",
    "df0.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the first few rows of `nyc_preds_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.616667</td>\n",
       "      <td>4.435000</td>\n",
       "      <td>15.845642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.855376</td>\n",
       "      <td>2.052258</td>\n",
       "      <td>10.441351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59.633333</td>\n",
       "      <td>12.830000</td>\n",
       "      <td>45.374542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.437500</td>\n",
       "      <td>4.022500</td>\n",
       "      <td>18.555128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.873457</td>\n",
       "      <td>1.019259</td>\n",
       "      <td>7.151511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.541111</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>9.122755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_duration  mean_distance  predicted_fare\n",
       "0      22.847222       3.521667       16.434245\n",
       "1      24.470370       3.108889       16.052218\n",
       "2       7.250000       0.881429        7.053706\n",
       "3      30.250000       3.700000       18.731650\n",
       "4      14.616667       4.435000       15.845642\n",
       "5      11.855376       2.052258       10.441351\n",
       "6      59.633333      12.830000       45.374542\n",
       "7      26.437500       4.022500       18.555128\n",
       "8       7.873457       1.019259        7.151511\n",
       "9      10.541111       1.580000        9.122755"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first few rows of `nyc_preds_means`\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "nyc_preds_means.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Join the two dataframes\n",
    "\n",
    "Join the two dataframes using a method of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "df0=pd.concat([df0,nyc_preds_means],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24870114</th>\n",
       "      <td>2.0</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>100.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634249</th>\n",
       "      <td>1.0</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106203690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>262.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38942136</th>\n",
       "      <td>2.0</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>188.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30841670</th>\n",
       "      <td>2.0</td>\n",
       "      <td>04/15/2017 11:32:20 PM</td>\n",
       "      <td>04/15/2017 11:49:03 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.594643</td>\n",
       "      <td>1.098214</td>\n",
       "      <td>7.799138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22695</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.560417</td>\n",
       "      <td>18.757500</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22696</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.609091</td>\n",
       "      <td>0.684242</td>\n",
       "      <td>6.130896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22697</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.650000</td>\n",
       "      <td>2.077500</td>\n",
       "      <td>11.707049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22698</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.405556</td>\n",
       "      <td>1.476970</td>\n",
       "      <td>8.600969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45398 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  \\\n",
       "24870114        2.0   03/25/2017 8:55:43 AM   03/25/2017 9:09:47 AM   \n",
       "35634249        1.0   04/11/2017 2:53:28 PM   04/11/2017 3:19:58 PM   \n",
       "106203690       1.0   12/15/2017 7:26:56 AM   12/15/2017 7:34:08 AM   \n",
       "38942136        2.0   05/07/2017 1:17:59 PM   05/07/2017 1:48:14 PM   \n",
       "30841670        2.0  04/15/2017 11:32:20 PM  04/15/2017 11:49:03 PM   \n",
       "...             ...                     ...                     ...   \n",
       "22694           NaN                     NaN                     NaN   \n",
       "22695           NaN                     NaN                     NaN   \n",
       "22696           NaN                     NaN                     NaN   \n",
       "22697           NaN                     NaN                     NaN   \n",
       "22698           NaN                     NaN                     NaN   \n",
       "\n",
       "           passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "24870114               6.0           3.34         1.0                  N   \n",
       "35634249               1.0           1.80         1.0                  N   \n",
       "106203690              1.0           1.00         1.0                  N   \n",
       "38942136               1.0           3.70         1.0                  N   \n",
       "30841670               1.0           4.37         1.0                  N   \n",
       "...                    ...            ...         ...                ...   \n",
       "22694                  NaN            NaN         NaN                NaN   \n",
       "22695                  NaN            NaN         NaN                NaN   \n",
       "22696                  NaN            NaN         NaN                NaN   \n",
       "22697                  NaN            NaN         NaN                NaN   \n",
       "22698                  NaN            NaN         NaN                NaN   \n",
       "\n",
       "           PULocationID  DOLocationID  payment_type  fare_amount  extra  \\\n",
       "24870114          100.0         231.0           1.0         13.0    0.0   \n",
       "35634249          186.0          43.0           1.0         16.0    0.0   \n",
       "106203690         262.0         236.0           1.0          6.5    0.0   \n",
       "38942136          188.0          97.0           1.0         20.5    0.0   \n",
       "30841670            4.0         112.0           2.0         16.5    0.5   \n",
       "...                 ...           ...           ...          ...    ...   \n",
       "22694               NaN           NaN           NaN          NaN    NaN   \n",
       "22695               NaN           NaN           NaN          NaN    NaN   \n",
       "22696               NaN           NaN           NaN          NaN    NaN   \n",
       "22697               NaN           NaN           NaN          NaN    NaN   \n",
       "22698               NaN           NaN           NaN          NaN    NaN   \n",
       "\n",
       "           mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "24870114       0.5        2.76           0.0                    0.3   \n",
       "35634249       0.5        4.00           0.0                    0.3   \n",
       "106203690      0.5        1.45           0.0                    0.3   \n",
       "38942136       0.5        6.39           0.0                    0.3   \n",
       "30841670       0.5        0.00           0.0                    0.3   \n",
       "...            ...         ...           ...                    ...   \n",
       "22694          NaN         NaN           NaN                    NaN   \n",
       "22695          NaN         NaN           NaN                    NaN   \n",
       "22696          NaN         NaN           NaN                    NaN   \n",
       "22697          NaN         NaN           NaN                    NaN   \n",
       "22698          NaN         NaN           NaN                    NaN   \n",
       "\n",
       "           total_amount  mean_duration  mean_distance  predicted_fare  \n",
       "24870114          16.56            NaN            NaN             NaN  \n",
       "35634249          20.80            NaN            NaN             NaN  \n",
       "106203690          8.75            NaN            NaN             NaN  \n",
       "38942136          27.69            NaN            NaN             NaN  \n",
       "30841670          17.80            NaN            NaN             NaN  \n",
       "...                 ...            ...            ...             ...  \n",
       "22694               NaN       8.594643       1.098214        7.799138  \n",
       "22695               NaN      59.560417      18.757500       52.000000  \n",
       "22696               NaN       6.609091       0.684242        6.130896  \n",
       "22697               NaN      16.650000       2.077500       11.707049  \n",
       "22698               NaN       9.405556       1.476970        8.600969  \n",
       "\n",
       "[45398 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgPRBjizg1oo"
   },
   "source": [
    "<img src=\"images/Analyze.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## PACE: **Analyze**\n",
    "\n",
    "Consider the questions in your PACE Strategy Documentto reflect on the Analyze stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VZowX9rhU1o"
   },
   "source": [
    "### **Task 2. Feature engineering**\n",
    "\n",
    "You have already prepared much of this data and performed exploratory data analysis (EDA) in previous courses. \n",
    "\n",
    "Call `info()` on the new combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mBOSW8IDbO_d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45398 entries, 24870114 to 22698\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   VendorID               22699 non-null  float64\n",
      " 1   tpep_pickup_datetime   22699 non-null  object \n",
      " 2   tpep_dropoff_datetime  22699 non-null  object \n",
      " 3   passenger_count        22699 non-null  float64\n",
      " 4   trip_distance          22699 non-null  float64\n",
      " 5   RatecodeID             22699 non-null  float64\n",
      " 6   store_and_fwd_flag     22699 non-null  object \n",
      " 7   PULocationID           22699 non-null  float64\n",
      " 8   DOLocationID           22699 non-null  float64\n",
      " 9   payment_type           22699 non-null  float64\n",
      " 10  fare_amount            22699 non-null  float64\n",
      " 11  extra                  22699 non-null  float64\n",
      " 12  mta_tax                22699 non-null  float64\n",
      " 13  tip_amount             22699 non-null  float64\n",
      " 14  tolls_amount           22699 non-null  float64\n",
      " 15  improvement_surcharge  22699 non-null  float64\n",
      " 16  total_amount           22699 non-null  float64\n",
      " 17  mean_duration          22699 non-null  float64\n",
      " 18  mean_distance          22699 non-null  float64\n",
      " 19  predicted_fare         22699 non-null  float64\n",
      "dtypes: float64(17), object(3)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#==> ENTER YOUR CODE HERE\n",
    "df0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D2RvXk0kwsx"
   },
   "source": [
    "You know from your EDA that customers who pay cash generally have a tip amount of $0. To meet the modeling objective, you'll need to sample the data to select only the customers who pay with credit card. \n",
    "\n",
    "Copy `df0` and assign the result to a variable called `df1`. Then, use a Boolean mask to filter `df1` so it contains only customers who paid with credit card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_pmNd78plQYr"
   },
   "outputs": [],
   "source": [
    "# Subset the data to isolate only customers who paid by credit card\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "df0=df0[df0['payment_type']==1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24870114</th>\n",
       "      <td>2.0</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>100.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634249</th>\n",
       "      <td>1.0</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106203690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>262.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38942136</th>\n",
       "      <td>2.0</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>188.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23345809</th>\n",
       "      <td>2.0</td>\n",
       "      <td>03/25/2017 8:34:11 PM</td>\n",
       "      <td>03/25/2017 8:42:11 PM</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60425673</th>\n",
       "      <td>1.0</td>\n",
       "      <td>07/16/2017 3:22:51 AM</td>\n",
       "      <td>07/16/2017 3:40:52 AM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>249.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67858616</th>\n",
       "      <td>2.0</td>\n",
       "      <td>08/10/2017 10:20:04 PM</td>\n",
       "      <td>08/10/2017 10:29:31 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>229.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66632549</th>\n",
       "      <td>2.0</td>\n",
       "      <td>08/06/2017 4:43:59 PM</td>\n",
       "      <td>08/06/2017 5:24:47 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14.64</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.3</td>\n",
       "      <td>73.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60217333</th>\n",
       "      <td>2.0</td>\n",
       "      <td>07/15/2017 12:56:30 PM</td>\n",
       "      <td>07/15/2017 1:08:26 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17208911</th>\n",
       "      <td>1.0</td>\n",
       "      <td>03/02/2017 1:02:49 PM</td>\n",
       "      <td>03/02/2017 1:16:09 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15265 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  \\\n",
       "24870114        2.0   03/25/2017 8:55:43 AM   03/25/2017 9:09:47 AM   \n",
       "35634249        1.0   04/11/2017 2:53:28 PM   04/11/2017 3:19:58 PM   \n",
       "106203690       1.0   12/15/2017 7:26:56 AM   12/15/2017 7:34:08 AM   \n",
       "38942136        2.0   05/07/2017 1:17:59 PM   05/07/2017 1:48:14 PM   \n",
       "23345809        2.0   03/25/2017 8:34:11 PM   03/25/2017 8:42:11 PM   \n",
       "...             ...                     ...                     ...   \n",
       "60425673        1.0   07/16/2017 3:22:51 AM   07/16/2017 3:40:52 AM   \n",
       "67858616        2.0  08/10/2017 10:20:04 PM  08/10/2017 10:29:31 PM   \n",
       "66632549        2.0   08/06/2017 4:43:59 PM   08/06/2017 5:24:47 PM   \n",
       "60217333        2.0  07/15/2017 12:56:30 PM   07/15/2017 1:08:26 PM   \n",
       "17208911        1.0   03/02/2017 1:02:49 PM   03/02/2017 1:16:09 PM   \n",
       "\n",
       "           passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "24870114               6.0           3.34         1.0                  N   \n",
       "35634249               1.0           1.80         1.0                  N   \n",
       "106203690              1.0           1.00         1.0                  N   \n",
       "38942136               1.0           3.70         1.0                  N   \n",
       "23345809               6.0           2.30         1.0                  N   \n",
       "...                    ...            ...         ...                ...   \n",
       "60425673               1.0           5.70         1.0                  N   \n",
       "67858616               1.0           0.89         1.0                  N   \n",
       "66632549               1.0          16.71         2.0                  N   \n",
       "60217333               1.0           2.36         1.0                  N   \n",
       "17208911               1.0           2.10         1.0                  N   \n",
       "\n",
       "           PULocationID  DOLocationID  payment_type  fare_amount  extra  \\\n",
       "24870114          100.0         231.0           1.0         13.0    0.0   \n",
       "35634249          186.0          43.0           1.0         16.0    0.0   \n",
       "106203690         262.0         236.0           1.0          6.5    0.0   \n",
       "38942136          188.0          97.0           1.0         20.5    0.0   \n",
       "23345809          161.0         236.0           1.0          9.0    0.5   \n",
       "...                 ...           ...           ...          ...    ...   \n",
       "60425673          249.0          17.0           1.0         19.0    0.5   \n",
       "67858616          229.0         170.0           1.0          7.5    0.5   \n",
       "66632549          132.0         164.0           1.0         52.0    0.0   \n",
       "60217333           68.0         144.0           1.0         10.5    0.0   \n",
       "17208911          239.0         236.0           1.0         11.0    0.0   \n",
       "\n",
       "           mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "24870114       0.5        2.76          0.00                    0.3   \n",
       "35634249       0.5        4.00          0.00                    0.3   \n",
       "106203690      0.5        1.45          0.00                    0.3   \n",
       "38942136       0.5        6.39          0.00                    0.3   \n",
       "23345809       0.5        2.06          0.00                    0.3   \n",
       "...            ...         ...           ...                    ...   \n",
       "60425673       0.5        4.05          0.00                    0.3   \n",
       "67858616       0.5        1.76          0.00                    0.3   \n",
       "66632549       0.5       14.64          5.76                    0.3   \n",
       "60217333       0.5        1.70          0.00                    0.3   \n",
       "17208911       0.5        2.35          0.00                    0.3   \n",
       "\n",
       "           total_amount  mean_duration  mean_distance  predicted_fare  \n",
       "24870114          16.56            NaN            NaN             NaN  \n",
       "35634249          20.80            NaN            NaN             NaN  \n",
       "106203690          8.75            NaN            NaN             NaN  \n",
       "38942136          27.69            NaN            NaN             NaN  \n",
       "23345809          12.36            NaN            NaN             NaN  \n",
       "...                 ...            ...            ...             ...  \n",
       "60425673          24.35            NaN            NaN             NaN  \n",
       "67858616          10.56            NaN            NaN             NaN  \n",
       "66632549          73.20            NaN            NaN             NaN  \n",
       "60217333          13.00            NaN            NaN             NaN  \n",
       "17208911          14.15            NaN            NaN             NaN  \n",
       "\n",
       "[15265 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcYudtSYyMcZ"
   },
   "source": [
    "##### **Target**\n",
    "\n",
    "Notice that there isn't a column that indicates tip percent, which is what you need to create the target variable. You'll have to engineer it. \n",
    "\n",
    "Add a `tip_percent` column to the dataframe by performing the following calculation:  \n",
    "<br/>  \n",
    "\n",
    "\n",
    "$$tip\\ percent = \\frac{tip\\ amount}{total\\ amount - tip\\ amount}$$  \n",
    "\n",
    "Round the result to three places beyond the decimal. **This is an important step.** It affects how many customers are labeled as generous tippers. In fact, without performing this step, approximately 1,800 people who do tip ≥ 20% would be labeled as not generous. \n",
    "\n",
    "To understand why, you must consider how floats work. Computers make their calculations using floating-point arithmetic (hence the word \"float\"). Floating-point arithmetic is a system that allows computers to express both very large numbers and very small numbers with a high degree of precision, encoded in binary. However, precision is limited by the number of bits used to represent a number, which is generally 32 or 64, depending on the capabilities of your operating system. \n",
    "\n",
    "This comes with limitations in that sometimes calculations that should result in clean, precise values end up being encoded as very long decimals. Take, for example, the following calculation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24870114      2.76\n",
       "35634249      4.00\n",
       "106203690     1.45\n",
       "38942136      6.39\n",
       "23345809      2.06\n",
       "             ...  \n",
       "60425673      4.05\n",
       "67858616      1.76\n",
       "66632549     14.64\n",
       "60217333      1.70\n",
       "17208911      2.35\n",
       "Name: tip_percent, Length: 15265, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell\n",
    "1.1 + 2.2\n",
    "df0['tip_percent']=df0['tip_amount']/(df0['total_amount']-df0['tip_amount'])\n",
    "df0['tip_percent']=df0['tip_amount'].apply(lambda x: round(float(x),3))\n",
    "df0['tip_percent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the three that is 16 places to the right of the decimal. As a consequence, if you were to then have a step in your code that identifies values ≤ 3.3, this would not be included in the result. Therefore, whenever you perform a calculation to compute a number that is then used to make an important decision or filtration, round the number. How many degrees of precision you round to is your decision, which should be based on your use case. \n",
    "\n",
    "Refer to this [guide for more information related to floating-point arithmetic](https://floating-point-gui.de/formats/fp/).  \n",
    "Refer to this [guide for more information related to fixed-point arithmetic](https://inst.eecs.berkeley.edu/~cs61c/sp06/handout/fixedpt.html), which is an alternative to floating-point arithmetic used in certain cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "guanzJd8zBla"
   },
   "outputs": [],
   "source": [
    "# Create tip % col\n",
    "#==> ENTER YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqb-SWfs-8Xn"
   },
   "source": [
    "\n",
    "Now create another column called `generous`. This will be the target variable. The column should be a binary indicator of whether or not a customer tipped ≥ 20% (0=no, 1=yes).\n",
    "\n",
    "1. Begin by making the `generous` column a copy of the `tip_percent` column.\n",
    "2. Reassign the column by converting it to Boolean (True/False).\n",
    "3. Reassign the column by converting Boolean to binary (1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nqDSe0DSGwhB"
   },
   "outputs": [],
   "source": [
    "# Create 'generous' col (target)\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "df0['generous']=pd.Series([])\n",
    "df0['generous'][df0['tip_percent']>df0['tip_percent'].sum()**0.2]=0\n",
    "df0['generous'][df0['tip_percent']<df0['tip_percent'].sum()**0.2]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24870114     1.0\n",
       "35634249     1.0\n",
       "106203690    1.0\n",
       "38942136     1.0\n",
       "23345809     1.0\n",
       "            ... \n",
       "60425673     1.0\n",
       "67858616     1.0\n",
       "66632549     0.0\n",
       "60217333     1.0\n",
       "17208911     1.0\n",
       "Name: generous, Length: 15265, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['generous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddLE6KE1KeF7"
   },
   "source": [
    "\n",
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "To convert from Boolean to binary, use `.astype(int)` on the column.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create day column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H27zUVIlkaxA"
   },
   "source": [
    "Next, you're going to be working with the pickup and dropoff columns.\n",
    "\n",
    "Convert the `tpep_pickup_datetime` and `tpep_dropoff_datetime` columns to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OIycxWBMkafJ"
   },
   "outputs": [],
   "source": [
    "# Convert pickup and dropoff cols to datetime\n",
    "#==> ENTER YOUR CODE HERE\n",
    "import datetime\n",
    "\n",
    "\n",
    "df0['tpep_pickup_datetime']=df0['tpep_pickup_datetime'].apply(lambda x: datetime.datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['tpep_dropoff_datetime']=df0['tpep_dropoff_datetime'].apply(lambda x: datetime.datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpcM4FvNyPFY"
   },
   "source": [
    "\n",
    "Create a `day` column that contains only the day of the week when each passenger was picked up. Then, convert the values to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "abUvtMaYyWpD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24870114     saturday\n",
       "35634249      tuesday\n",
       "106203690      friday\n",
       "38942136       sunday\n",
       "23345809     saturday\n",
       "               ...   \n",
       "60425673       sunday\n",
       "67858616     thursday\n",
       "66632549       sunday\n",
       "60217333     saturday\n",
       "17208911     thursday\n",
       "Name: tpep_pickup_datetime_1_d, Length: 15265, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 'day' col\n",
    "#==> ENTER YOUR CODE HERE\n",
    "df0['tpep_pickup_datetime_1']=pd.to_datetime(df0['tpep_pickup_datetime'])\n",
    "df0['tpep_pickup_datetime_1_d']=df0['tpep_pickup_datetime_1'].apply(lambda x: x.day_name())\n",
    "df0['tpep_pickup_datetime_1_d']=df0['tpep_pickup_datetime_1_d'].apply(lambda x: x.lower())\n",
    "df0['tpep_pickup_datetime_1_d']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZZhKnQrQgNM"
   },
   "source": [
    "\n",
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "To convert to day name, use `dt.day_name()` on the column.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time of day columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwslVt8Hpu7x"
   },
   "source": [
    "Next, engineer four new columns that represent time of day bins. Each column should contain binary values (0=no, 1=yes) that indicate whether a trip began (picked up) during the following times:\n",
    "\n",
    "`am_rush` = [06:00&ndash;10:00)  \n",
    "`daytime` = [10:00&ndash;16:00)  \n",
    "`pm_rush` = [16:00&ndash;20:00)  \n",
    "`nighttime` = [20:00&ndash;06:00)  \n",
    "\n",
    "To do this, first create the four columns. For now, each new column should be identical and contain the same information: the hour (only) from the `tpep_pickup_datetime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "x8LFySUyprau"
   },
   "outputs": [],
   "source": [
    "# Create 'am_rush' col\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "df0['tpep_pickup_datetime']=df0['tpep_pickup_datetime'].apply(lambda x: datetime.datetime.strftime(x, '%m/%d/%Y %H:%M:%S %p'))\n",
    "df0['tpep_pickup_datetime']=df0['tpep_pickup_datetime'].apply(lambda x: datetime.datetime.strptime(x,'%m/%d/%Y %H:%M:%S %p'))\n",
    "df0['tpep_pickup_datetime_month']=df0['tpep_pickup_datetime'].apply(lambda x: x.hour)\n",
    "df0.loc[(df0['tpep_pickup_datetime_month']<=10.0) & (df0['tpep_pickup_datetime_month']>=6.0),'tme_of_day']='am_rush'\n",
    "df0.loc[(df0['tpep_pickup_datetime_month']<=16.0) & (df0['tpep_pickup_datetime_month']>=10.0) , 'tme_of_day']='daytime'\n",
    "df0.loc[(df0['tpep_pickup_datetime_month']<=20.0) & (df0['tpep_pickup_datetime_month']>=16.0) , 'tme_of_day']='pm_rush'\n",
    "df0.loc[ (df0['tpep_pickup_datetime_month']>=df0['tpep_pickup_datetime_month'].max()) & (df0['tpep_pickup_datetime_month']<=6.0) , 'tme_of_day']='nighttime'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pm_rush    4451\n",
       "daytime    4288\n",
       "am_rush    2480\n",
       "Name: tme_of_day, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['tme_of_day'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDyfsTDvwORL"
   },
   "source": [
    "You'll need to write four functions to convert each new column to binary (0/1). Begin with `am_rush`. Complete the function so if the hour is between [06:00–10:00), it returns 1, otherwise, it returns 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oAE4vRz0wGtN"
   },
   "outputs": [],
   "source": [
    "# Define 'am_rush()' conversion function [06:00–10:00)\n",
    "    #==> ENTER YOUR CODE HERE\n",
    "def am_rush(x,y):\n",
    "    df0[y]=pd.Series([])\n",
    "    df0.loc[df0[x]==y,y]=1.0\n",
    "    df0[y].fillna(0.0,inplace=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHY1-6cIxfA6"
   },
   "source": [
    "Now, apply the `am_rush()` function to the `am_rush` series to perform the conversion. Print the first five values of the column to make sure it did what you expected it to do.\n",
    "\n",
    "**Note:** Be careful! If you run this cell twice, the function will be reapplied and the values will all be changed to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "sWFojyk9xdDY"
   },
   "outputs": [],
   "source": [
    "# Apply 'am_rush' function to the 'am_rush' series\n",
    "#==> ENTER YOUR CODE HERE\n",
    "am_rush('tme_of_day','am_rush')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSY6SsdK0lpn"
   },
   "source": [
    "Write functions to convert the three remaining columns and apply them to their respective series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UADnzaIjzwLG"
   },
   "outputs": [],
   "source": [
    "# Define 'daytime()' conversion function [10:00–16:00)\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "am_rush('tme_of_day','daytime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ReHpKxoC1Qsx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    10977\n",
       "1.0     4288\n",
       "Name: daytime, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply 'daytime()' function to the 'daytime' series\n",
    "#==> ENTER YOUR CODE HERE\n",
    "df0['daytime'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rP-ZBOHT1WQY"
   },
   "outputs": [],
   "source": [
    "# Define 'pm_rush()' conversion function [16:00–20:00)\n",
    "#==> ENTER YOUR CODE HERE\n",
    "am_rush('tme_of_day','pm_rush')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "h0zWPBqr1mX4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    10814\n",
       "1.0     4451\n",
       "Name: pm_rush, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply 'pm_rush()' function to the 'pm_rush' series\n",
    "#==> ENTER YOUR CODE HERE\n",
    "df0['pm_rush'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "u5O0LPLz2CSa"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define 'nighttime()' conversion function [20:00–06:00)\n",
    "#==> ENTER YOUR CODE HERE\n",
    "am_rush('tme_of_day','nighttime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kLGmBXkT2RTi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    15265\n",
       "Name: nighttime, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Apply 'nighttime' function to the 'nighttime' series\n",
    "#==> ENTER YOUR CODE HERE\n",
    "df0['nighttime'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `month` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrUmDy8U28bs"
   },
   "source": [
    "Now, create a `month` column that contains only the abbreviated name of the month when each passenger was picked up, then convert the result to lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bU5Zchdxgk3w"
   },
   "source": [
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "Refer to the [strftime cheatsheet](https://strftime.org/) for help.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24870114      3\n",
       "35634249      4\n",
       "106203690    12\n",
       "38942136      5\n",
       "23345809      3\n",
       "             ..\n",
       "60425673      7\n",
       "67858616      8\n",
       "66632549      8\n",
       "60217333      7\n",
       "17208911      3\n",
       "Name: month, Length: 15265, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 'month' col\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "df0['month']=df0['tpep_pickup_datetime'].apply(lambda x: x.month)\n",
    "df0['month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWbNVbngihE6"
   },
   "source": [
    "\n",
    "Examine the first five rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jWxemeyl4vwQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "      <th>tip_percent</th>\n",
       "      <th>generous</th>\n",
       "      <th>tpep_pickup_datetime_1</th>\n",
       "      <th>tpep_pickup_datetime_1_d</th>\n",
       "      <th>tpep_pickup_datetime_month</th>\n",
       "      <th>tme_of_day</th>\n",
       "      <th>am_rush</th>\n",
       "      <th>daytime</th>\n",
       "      <th>pm_rush</th>\n",
       "      <th>nighttime</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24870114</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-25 08:55:43</td>\n",
       "      <td>2017-03-25 09:09:47</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>100.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-25 08:55:43</td>\n",
       "      <td>saturday</td>\n",
       "      <td>8</td>\n",
       "      <td>am_rush</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634249</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-04-11 14:53:28</td>\n",
       "      <td>2017-04-11 15:19:58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-04-11 14:53:28</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>14</td>\n",
       "      <td>daytime</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106203690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-12-15 07:26:56</td>\n",
       "      <td>2017-12-15 07:34:08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>262.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-12-15 07:26:56</td>\n",
       "      <td>friday</td>\n",
       "      <td>7</td>\n",
       "      <td>am_rush</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38942136</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-05-07 13:17:59</td>\n",
       "      <td>2017-05-07 13:48:14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>188.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-05-07 13:17:59</td>\n",
       "      <td>sunday</td>\n",
       "      <td>13</td>\n",
       "      <td>daytime</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23345809</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-03-25 20:34:11</td>\n",
       "      <td>2017-03-25 20:42:11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-25 20:34:11</td>\n",
       "      <td>saturday</td>\n",
       "      <td>20</td>\n",
       "      <td>pm_rush</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "24870114        2.0  2017-03-25 08:55:43   2017-03-25 09:09:47   \n",
       "35634249        1.0  2017-04-11 14:53:28   2017-04-11 15:19:58   \n",
       "106203690       1.0  2017-12-15 07:26:56   2017-12-15 07:34:08   \n",
       "38942136        2.0  2017-05-07 13:17:59   2017-05-07 13:48:14   \n",
       "23345809        2.0  2017-03-25 20:34:11   2017-03-25 20:42:11   \n",
       "\n",
       "           passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "24870114               6.0           3.34         1.0                  N   \n",
       "35634249               1.0           1.80         1.0                  N   \n",
       "106203690              1.0           1.00         1.0                  N   \n",
       "38942136               1.0           3.70         1.0                  N   \n",
       "23345809               6.0           2.30         1.0                  N   \n",
       "\n",
       "           PULocationID  DOLocationID  payment_type  fare_amount  extra  \\\n",
       "24870114          100.0         231.0           1.0         13.0    0.0   \n",
       "35634249          186.0          43.0           1.0         16.0    0.0   \n",
       "106203690         262.0         236.0           1.0          6.5    0.0   \n",
       "38942136          188.0          97.0           1.0         20.5    0.0   \n",
       "23345809          161.0         236.0           1.0          9.0    0.5   \n",
       "\n",
       "           mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "24870114       0.5        2.76           0.0                    0.3   \n",
       "35634249       0.5        4.00           0.0                    0.3   \n",
       "106203690      0.5        1.45           0.0                    0.3   \n",
       "38942136       0.5        6.39           0.0                    0.3   \n",
       "23345809       0.5        2.06           0.0                    0.3   \n",
       "\n",
       "           total_amount  mean_duration  mean_distance  predicted_fare  \\\n",
       "24870114          16.56            NaN            NaN             NaN   \n",
       "35634249          20.80            NaN            NaN             NaN   \n",
       "106203690          8.75            NaN            NaN             NaN   \n",
       "38942136          27.69            NaN            NaN             NaN   \n",
       "23345809          12.36            NaN            NaN             NaN   \n",
       "\n",
       "           tip_percent  generous tpep_pickup_datetime_1  \\\n",
       "24870114          2.76       1.0    2017-03-25 08:55:43   \n",
       "35634249          4.00       1.0    2017-04-11 14:53:28   \n",
       "106203690         1.45       1.0    2017-12-15 07:26:56   \n",
       "38942136          6.39       1.0    2017-05-07 13:17:59   \n",
       "23345809          2.06       1.0    2017-03-25 20:34:11   \n",
       "\n",
       "          tpep_pickup_datetime_1_d  tpep_pickup_datetime_month tme_of_day  \\\n",
       "24870114                  saturday                           8    am_rush   \n",
       "35634249                   tuesday                          14    daytime   \n",
       "106203690                   friday                           7    am_rush   \n",
       "38942136                    sunday                          13    daytime   \n",
       "23345809                  saturday                          20    pm_rush   \n",
       "\n",
       "           am_rush  daytime  pm_rush  nighttime  month  \n",
       "24870114       1.0      0.0      0.0        0.0      3  \n",
       "35634249       0.0      1.0      0.0        0.0      4  \n",
       "106203690      1.0      0.0      0.0        0.0     12  \n",
       "38942136       0.0      1.0      0.0        0.0      5  \n",
       "23345809       0.0      0.0      1.0        0.0      3  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "pd.set_option('display.max_column',5165)\n",
    "df0[['mean_duration','mean_distance','predicted_fare']].fillna(0,inplace=True)\n",
    "df0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns\n",
    "\n",
    "Drop redundant and irrelevant columns as well as those that would not be available when the model is deployed. This includes information like payment type, trip distance, tip amount, tip percentage, total amount, toll amount, etc. The target variable (`generous`) must remain in the data because it will get isolated as the `y` data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "df0.drop(['tpep_pickup_datetime_1_d','tpep_pickup_datetime_month','tpep_pickup_datetime','tpep_dropoff_datetime','VendorID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVs01W-Iitu7"
   },
   "source": [
    "\n",
    "Many of the columns are categorical and will need to be dummied (converted to binary). Some of these columns are numeric, but they actually encode categorical information, such as `RatecodeID` and the pickup and dropoff locations. To make these columns recognizable to the `get_dummies()` function as categorical variables, you'll first need to convert them to `type(str)`. \n",
    "\n",
    "1. Define a variable called `cols_to_str`, which is a list of the numeric columns that contain categorical information and must be converted to string: `RatecodeID`, `PULocationID`, `DOLocationID`.\n",
    "2. Write a for loop that converts each column in `cols_to_str` to string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FbB4AfATHqjC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24870114     1\n",
       "35634249     2\n",
       "106203690    1\n",
       "38942136     2\n",
       "23345809     3\n",
       "            ..\n",
       "60425673     0\n",
       "67858616     0\n",
       "66632549     3\n",
       "60217333     2\n",
       "17208911     2\n",
       "Name: tme_of_day, Length: 15265, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define list of cols to convert to string\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "\n",
    "# 2. Convert each column to string\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "model_l=LabelEncoder()\n",
    "df0['tme_of_day'].fillna(' ',inplace=True)\n",
    "df0['tme_of_day']=model_l.fit_transform(df0['tme_of_day'])\n",
    "df0['tme_of_day']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j6Nyb5RnsvC"
   },
   "source": [
    "\n",
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "To convert to string, use `astype(str)` on the column.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5Ubw8O1pKRO"
   },
   "source": [
    "Now convert all the categorical columns to binary.\n",
    "\n",
    "1. Call `get_dummies()` on the dataframe and assign the results back to a new dataframe called `df2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "H94yLzUMHqgB"
   },
   "outputs": [],
   "source": [
    "# Convert categoricals to binary\n",
    "#==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZfNE37b-LlJ"
   },
   "source": [
    "##### Evaluation metric\n",
    "\n",
    "Before modeling, you must decide on an evaluation metric. \n",
    "\n",
    "1. Examine the class balance of your target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4mRefXCF-K_c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x79826b6f0f10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get class balance of 'generous' col\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(df0['generous'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjgkLrOf_OrE"
   },
   "source": [
    "A little over half of the customers in this dataset were \"generous\" (tipped ≥ 20%). The dataset is very nearly balanced.\n",
    "\n",
    "To determine a metric, consider the cost of both kinds of model error:\n",
    "* False positives (the model predicts a tip ≥ 20%, but the customer does not give one)\n",
    "* False negatives (the model predicts a tip < 20%, but the customer gives more)\n",
    "\n",
    "False positives are worse for cab drivers, because they would pick up a customer expecting a good tip and then not receive one, frustrating the driver.\n",
    "\n",
    "False negatives are worse for customers, because a cab driver would likely pick up a different customer who was predicted to tip more&mdash;even when the original customer would have tipped generously.\n",
    "\n",
    "**The stakes are relatively even. You want to help taxi drivers make more money, but you don't want this to anger customers. Your metric should weigh both precision and recall equally. Which metric is this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model predicts a customer who is generous as not generous one, the cab driver would not select to pick up that customer which will result in the loss of receiving a good tip. For the customer, who is expecting a pick up will be frustated \n",
    "\n",
    "But when the same model predicts a customer as generous but infact is not generous, then the cab driver would pick up a customer\n",
    "expecting a good tip but not receive one. For the customer, who is expecting a pick up will not be frustated\n",
    "\n",
    "so in both cases, we should select the first one as the priority False positives should be the priority instead of false negatives because both the customer and drivers are facing issues as one gets frustated and other doesn't get any good tip.\n",
    "\n",
    "False negatives are bad for drivers as they recieve bad tips. \n",
    "\n",
    "If the drivers have options to not select the pick ups, then in that case False positives has priority as here both the drivers are customers both are facing severe problems compared to false negatives\n",
    "\n",
    "If in both cases are considered Flase positives have more prioirty than false negatives. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n1eikFh8akS"
   },
   "source": [
    "\n",
    "<img src=\"images/Construct.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## PACE: **Construct**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Construct stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5jzGjOS8iiv"
   },
   "source": [
    "### **Task 3. Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx41bVxX89Fe"
   },
   "source": [
    "##### **Split the data**\n",
    "\n",
    "Now you're ready to model. The only remaining step is to split the data into features/target variable and training/testing data. \n",
    "\n",
    "1. Define a variable `y` that isolates the target variable (`generous`).\n",
    "2. Define a variable `X` that isolates the features.\n",
    "3. Split the data into training and testing sets. Put 20% of the samples into the test set, stratify the data, and set the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qLbapbSWDUL-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32151502     1.0\n",
       "14872875     1.0\n",
       "83439433     1.0\n",
       "111318817    1.0\n",
       "81103661     1.0\n",
       "            ... \n",
       "563347       1.0\n",
       "1482800      1.0\n",
       "48599611     1.0\n",
       "52619780     1.0\n",
       "89734054     1.0\n",
       "Name: generous, Length: 6106, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate target variable (y)\n",
    "#==> ENTER YOUR CODE HERE\n",
    "y=df0['generous']\n",
    "\n",
    "# Isolate the features (X)\n",
    "#==> ENTER YOUR CODE HERE\n",
    "X=df0\n",
    "X['store_and_fwd_flag']=model_l.fit_transform(X['store_and_fwd_flag'])\n",
    "X.fillna(0,inplace=True)\n",
    "X.drop('tpep_pickup_datetime_1',axis=1,inplace=True)\n",
    "\n",
    "# Split into train and test sets\n",
    "#==> ENTER YOUR CODE HERE\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.4)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vynZs5het1b_"
   },
   "source": [
    "##### **Random forest**\n",
    "\n",
    "Begin with using `GridSearchCV` to tune a random forest model.\n",
    "\n",
    "1. Instantiate the random forest classifier `rf` and set the random state.\n",
    "\n",
    "2. Create a dictionary `cv_params` of any of the following hyperparameters and their corresponding values to tune. The more you tune, the better your model will fit the data, but the longer it will take. \n",
    " - `max_depth`  \n",
    " - `max_features`  \n",
    " - `max_samples` \n",
    " - `min_samples_leaf`  \n",
    " - `min_samples_split`\n",
    " - `n_estimators`  \n",
    "\n",
    "3. Define a set `scoring` of scoring metrics for GridSearch to capture (precision, recall, F1 score, and accuracy).\n",
    "\n",
    "4. Instantiate the `GridSearchCV` object `rf1`. Pass to it as arguments:\n",
    " - estimator=`rf`\n",
    " - param_grid=`cv_params`\n",
    " - scoring=`scoring`\n",
    " - cv: define the number of you cross-validation folds you want (`cv=_`)\n",
    " - refit: indicate which evaluation metric you want to use to select the model (`refit=_`)\n",
    "\n",
    "\n",
    "**Note:** `refit` should be set to `'f1'`.<font/>\n",
    "</details>\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [1, 2, 3], 'max_features': [2, 5, 12],\n",
       "                         'max_samples': [69], 'min_samples_split': [5],\n",
       "                         'n_estimators': [145]},\n",
       "             pre_dispatch='2*n_jobs', refit='f1', return_train_score=False,\n",
       "             scoring={'accuracy', 'f1', 'precision', 'recall'}, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Instantiate the random forest classifier\n",
    "#==> ENTER YOUR CODE HERE\n",
    "rf=RandomForestClassifier(random_state=0)\n",
    "prams={'max_depth':[1,2,3],\n",
    "'max_features':[2,5,12],\n",
    "'max_samples':[69],\n",
    "'min_samples_split':[5],\n",
    "'n_estimators':[145]}\n",
    "\n",
    "scoring={'precision', 'recall', 'f1','accuracy'}\n",
    "\n",
    "rf1=GridSearchCV(rf,prams,scoring,cv=5,refit='f1')\n",
    "\n",
    "rf1.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune \n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "# 3. Define a set of scoring metrics to capture\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "#==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv_WvRA1RqTl"
   },
   "source": [
    "Now fit the model to the training data. Note that, depending on how many options you include in your search grid and the number of cross-validation folds you select, this could take a very long time&mdash;even hours. If you use 4-fold validation and include only one possible value for each hyperparameter and grow 300 trees to full depth, it should take about 5 minutes. If you add another value for GridSearch to check for, say, `min_samples_split` (so all hyperparameters now have 1 value except for `min_samples_split`, which has 2 possibilities), it would double the time to ~10 minutes. Each additional parameter would approximately double the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OXuBiTGi5ZHn"
   },
   "outputs": [],
   "source": [
    "#==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHi_YJduQOH"
   },
   "source": [
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "If you get a warning that a metric is 0 due to no predicted samples, think about how many features you're sampling with `max_features`. How many features are in the dataset? How many are likely predictive enough to give good predictions within the number of splits you've allowed (determined by the `max_depth` hyperparameter)? Consider increasing `max_features`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChZsXw2sksDF"
   },
   "source": [
    "If you want, use `pickle` to save your models and read them back in. This can be particularly helpful when performing a search over many possible hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "YtAgrH0zy4CE"
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Define a path to the folder where you want to save the model\n",
    "path = '/home/jovyan/work/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickle(path, model_object, save_name:str):\n",
    "    '''\n",
    "    save_name is a string.\n",
    "    '''\n",
    "    with open(path + save_name + '.pickle', 'wb') as to_write:\n",
    "        pickle.dump(model_object, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(path, saved_model_name:str):\n",
    "    '''\n",
    "    saved_model_name is a string.\n",
    "    '''\n",
    "    with open(path + saved_model_name + '.pickle', 'rb') as to_read:\n",
    "        model = pickle.load(to_read)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIaRiZW4hf-6"
   },
   "source": [
    "Examine the best average score across all the validation folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "29kGUegqhviL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseSearchCV.score of GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [1, 2, 3], 'max_features': [2, 5, 12],\n",
       "                         'max_samples': [69], 'min_samples_split': [5],\n",
       "                         'n_estimators': [145]},\n",
       "             pre_dispatch='2*n_jobs', refit='f1', return_train_score=False,\n",
       "             scoring={'accuracy', 'f1', 'precision', 'recall'}, verbose=0)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "rf1.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heGb51fHh3E5"
   },
   "source": [
    "Examine the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "FjgXbO7Kh8is"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=2, max_features=12,\n",
       "                       max_leaf_nodes=None, max_samples=69,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=145,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==> ENTER YOUR CODE HERE\n",
    "rf1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998287182415073"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2,\n",
       " 'max_features': 12,\n",
       " 'max_samples': 69,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 145}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.best_params_\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle('/home/jovyan/work/',rf1.best_estimator_,'RF_auto_grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZZnem5yiAau"
   },
   "source": [
    "Use the `make_results()` function to output all of the scores of your model. Note that it accepts three arguments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeW48TS742jN"
   },
   "source": [
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "To learn more about how this function accesses the cross-validation results, refer to the [`GridSearchCV` scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV) for the `cv_results_` attribute.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "u-UodWEOedxz"
   },
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "    model_name (string): what you want the model to be called in the output table\n",
    "    model_object: a fit GridSearchCV object\n",
    "    metric (string): precision, recall, f1, or accuracy\n",
    "\n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.\n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'precision': 'mean_test_precision',\n",
    "                 'recall': 'mean_test_recall',\n",
    "                 'f1': 'mean_test_f1',\n",
    "                 'accuracy': 'mean_test_accuracy',\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "\n",
    "    # Create table of results\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'precision': [precision],\n",
    "                        'recall': [recall],\n",
    "                        'F1': [f1],\n",
    "                        'accuracy': [accuracy],\n",
    "                        },\n",
    "                       )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI84Xo37ZLy0"
   },
   "source": [
    "Call `make_results()` on the GridSearch object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "qAYb2QigiT_h"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.999672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  precision  recall        F1  accuracy\n",
       "0  RandomForestClassifier   0.999658     1.0  0.999829  0.999672"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==> ENTER YOUR CODE HERE\n",
    "make_results('RandomForestClassifier', rf1, 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB-yhW9uu7dO"
   },
   "source": [
    "Your results should produce an acceptable model across the board. Typically scores of 0.65 or better are considered acceptable, but this is always dependent on your use case. Optional: try to improve the scores. It's worth trying, especially to practice searching over different hyperparameters.\n",
    "\n",
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "For example, if the available values for `min_samples_split` were [2, 3, 4] and GridSearch identified the best value as 4, consider trying [4, 5, 6] this time.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your model to predict on the test data. Assign the results to a variable called `rf_preds`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "    \n",
    "You cannot call `predict()` on the GridSearchCV object directly. You must call it on the `best_estimator_`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this project, you will use several models to predict on the test data. Remember that this decision comes with a trade-off. What is the benefit of this? What is the drawback?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycwjBHJjiT9J"
   },
   "source": [
    "==> ENTER YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "model=read_pickle(path,'RF_auto_grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below `get_test_scores()` function you will use to output the scores of the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(model_name:str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores.\n",
    "\n",
    "    In:\n",
    "    model_name (string): Your choice: how the model will be named in the output table\n",
    "    preds: numpy array of test predictions\n",
    "    y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "    table: a pandas df of precision, recall, f1, and accuracy scores for your model\n",
    "    '''\n",
    "    accuracy = accuracy_score(y_test_data, preds)\n",
    "    precision = precision_score(y_test_data, preds)\n",
    "    recall = recall_score(y_test_data, preds)\n",
    "    f1 = f1_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'precision': [precision],\n",
    "                        'recall': [recall],\n",
    "                        'F1': [f1],\n",
    "                        'accuracy': [accuracy]\n",
    "                        })\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDRAL7zQx21J"
   },
   "source": [
    "1. Use the `get_test_scores()` function to generate the scores on the test data. Assign the results to `rf_test_scores`.\n",
    "2. Call `rf_test_scores` to output the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RF test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Iil1LjabiT5x"
   },
   "outputs": [],
   "source": [
    " # Get scores on test data\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "y_pred=model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(ccp_alpha=0.0, class_w...</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998716</td>\n",
       "      <td>0.997543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  precision  recall  \\\n",
       "0  (DecisionTreeClassifier(ccp_alpha=0.0, class_w...   0.997436     1.0   \n",
       "\n",
       "         F1  accuracy  \n",
       "0  0.998716  0.997543  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_test_scores(model,y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4JiP5VRz2un"
   },
   "source": [
    "**Question:** How do your test results compare to your validation results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE6oXEJJiT2R"
   },
   "source": [
    "#==> ENTER YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **XGBoost**\n",
    "\n",
    " Try to improve your scores using an XGBoost model.\n",
    "\n",
    "1. Instantiate the XGBoost classifier `xgb` and set `objective='binary:logistic'`. Also set the random state.\n",
    "\n",
    "2. Create a dictionary `cv_params` of the following hyperparameters and their corresponding values to tune:\n",
    " - `max_depth`\n",
    " - `min_child_weight`\n",
    " - `learning_rate`\n",
    " - `n_estimators`\n",
    "\n",
    "3. Define a set `scoring` of scoring metrics for grid search to capture (precision, recall, F1 score, and accuracy).\n",
    "\n",
    "4. Instantiate the `GridSearchCV` object `xgb1`. Pass to it as arguments:\n",
    " - estimator=`xgb`\n",
    " - param_grid=`cv_params`\n",
    " - scoring=`scoring`\n",
    " - cv: define the number of cross-validation folds you want (`cv=_`)\n",
    " - refit: indicate which evaluation metric you want to use to select the model (`refit='f1'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective='binary:logistic',\n",
       "                                     predictor=None, random_state=0,\n",
       "                                     reg_alpha=None, ...),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [2], 'max_depth': [1, 2, 3],\n",
       "                         'min_child_weight': [2, 3], 'n_estimators': [25]},\n",
       "             pre_dispatch='2*n_jobs', refit='f1', return_train_score=False,\n",
       "             scoring={'accuracy', 'f1', 'precision', 'recall'}, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Instantiate the XGBoost classifier\n",
    "#==> ENTER YOUR CODE HERE\n",
    "# 1. Instantiate the random forest classifier\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune \n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "# 3. Define a set of scoring metrics to capture\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "\n",
    "xgb=XGBClassifier(random_state=0)\n",
    "prams={'max_depth':[1,2,3],\n",
    "'min_child_weight':[2,3],\n",
    "       'learning_rate':[2],\n",
    "       'n_estimators':[25]}\n",
    "\n",
    "scoring={'precision', 'recall', 'f1','accuracy'}\n",
    "\n",
    "rf1=GridSearchCV(xgb,prams,scoring,cv=5,refit='f1')\n",
    "\n",
    "rf1.fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the model to the `X_train` and `y_train` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#==> ENTER YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best score from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseSearchCV.score of GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective='binary:logistic',\n",
       "                                     predictor=None, random_state=0,\n",
       "                                     reg_alpha=None, ...),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [2], 'max_depth': [1, 2, 3],\n",
       "                         'min_child_weight': [2, 3], 'n_estimators': [25]},\n",
       "             pre_dispatch='2*n_jobs', refit='f1', return_train_score=False,\n",
       "             scoring={'accuracy', 'f1', 'precision', 'recall'}, verbose=0)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "#==> ENTER YOUR CODE HERE\n",
    "rf1.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bB-QyGz0RcU"
   },
   "source": [
    "And the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "JiLja3YViTzj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='', learning_rate=2,\n",
       "              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=1,\n",
       "              max_leaves=0, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=25, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='binary:logistic',\n",
       "              predictor='auto', random_state=0, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best parameters\n",
    "#==> ENTER YOUR CODE HERE\n",
    "rf1.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTE2QdNP0eEP"
   },
   "source": [
    "##### XGB CV Results\n",
    "\n",
    "Use the `make_results()` function to output all of the scores of your model. Note that it accepts three arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "L4TSYXJWiTxs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  precision    recall        F1  accuracy\n",
       "0  RandomForestClassifier   0.999886  0.999886  0.999886  0.999782"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "make_results('RandomForestClassifier', rf1, 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wR1QdIAX1dKX"
   },
   "source": [
    "Use your model to predict on the test data. Assign the results to a variable called `xgb_preds`.\n",
    "\n",
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "    \n",
    "You cannot call `predict()` on the GridSearchCV object directly. You must call it on the `best_estimator_`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "5Y2giCN32Dwc"
   },
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "xgb_preds=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEwnNMMP2Nbb"
   },
   "source": [
    "###### XGB test results\n",
    "\n",
    "1. Use the `get_test_scores()` function to generate the scores on the test data. Assign the results to `xgb_test_scores`.\n",
    "2. Call `xgb_test_scores` to output the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "g7jShC2TiTvx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(ccp_alpha=0.0, class_w...</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998716</td>\n",
       "      <td>0.997543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  precision  recall  \\\n",
       "0  (DecisionTreeClassifier(ccp_alpha=0.0, class_w...   0.997436     1.0   \n",
       "\n",
       "         F1  accuracy  \n",
       "0  0.998716  0.997543  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "get_test_scores(model,y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saM8YwbAyi-F"
   },
   "source": [
    "**Question:** Compare these scores to the random forest test scores. What do you notice? Which model would you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> ENTER YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCNH80Ku9TpO"
   },
   "source": [
    "Plot a confusion matrix of the model's predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "5iUyZWjWvqOd"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "confusion_matrix() got an unexpected keyword argument 'display_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-d4e9676bebc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#==> ENTER YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: confusion_matrix() got an unexpected keyword argument 'display_labels'"
     ]
    }
   ],
   "source": [
    "# Generate array of values for confusion matrix\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "# Plot confusion matrix\n",
    "#==> ENTER YOUR CODE HERE\n",
    "\n",
    "cm=confusion_matrix(y_test,y_pred,display_labels=None)\n",
    "\n",
    "disp=ConfusionMatrixDisplay(cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW-3_eWW-k2u"
   },
   "source": [
    "**Question:** What type of errors are more common for your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> ENTER YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNexnwvy09PK"
   },
   "source": [
    "##### Feature importance\n",
    "\n",
    "Use the `feature_importances_` attribute of the best estimator object to inspect the features of your final model. You can then sort them and plot the most important ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kz5T1gHc1R2x"
   },
   "outputs": [],
   "source": [
    "#==> ENTER YOUR CODE HERE\n",
    "model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HGsWfEOeWPm"
   },
   "source": [
    "<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## PACE: **Execute**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Execute stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ill21hQ4ej9-"
   },
   "source": [
    "### **Task 4. Conclusion**\n",
    "\n",
    "In this step, use the results of the models above to formulate a conclusion. Consider the following questions:\n",
    "\n",
    "1. **Would you recommend using this model? Why or why not?**  \n",
    "\n",
    "2. **What was your model doing? Can you explain how it was making predictions?**   \n",
    "\n",
    "3. **Are there new features that you can engineer that might improve model performance?**   \n",
    "\n",
    "4. **What features would you want to have that would likely improve the performance of your model?**   \n",
    "\n",
    "Remember, sometimes your data simply will not be predictive of your chosen target. This is common. Machine learning is a powerful tool, but it is not magic. If your data does not contain predictive signal, even the most complex algorithm will not be able to deliver consistent and accurate predictions. Do not be afraid to draw this conclusion. Even if you cannot use the model to make strong predictions, was the work done in vain? Consider any insights that you could report back to stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1oNheYh5WbljxkvoK_BMkQTey2DWnFXMs",
     "timestamp": 1663785370813
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
